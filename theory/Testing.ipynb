{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- testing theory overview:\n",
    "    - why: check that your code is valid\n",
    "    - unit tests: check only specific code (module, func), \"mock\" everyting else (use some stubs intead of real foreign functions)\n",
    "    - type, features: mock, fixtures, expect exceptions\n",
    "- doctest: the simplest way, + part of documentation (example of usage)\n",
    "- pytest (include pdb, benchmarking), unittest\n",
    "    - see some github repo (any big enough repo has tests =)) as an example\n",
    "    - see https://docs.python.org/3/library/pdb.html how to work with pdb\n",
    "- nose (simpler, than prevs, can be run even without any imports), tox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docs\n",
    "\n",
    "http://docs.python-guide.org/en/latest/writing/tests/\n",
    "\n",
    "### pytest\n",
    "\n",
    "http://pythontesting.net/start-here/\n",
    "https://docs.pytest.org/en/latest/\n",
    "https://semaphoreci.com/community/tutorials/testing-python-applications-with-pytest/\n",
    "\n",
    "### unittest\n",
    "\n",
    "http://pythontesting.net/framework/unittest/unittest-introduction/\n",
    "https://docs.python.org/3/library/unittest.html\n",
    "\n",
    "### nosetest\n",
    "\n",
    "http://pythontesting.net/framework/nose/nose-introduction/\n",
    "\n",
    "can run even very simpler functions without any extra stuff like:\n",
    "```python\n",
    "def test_numbers_3_4():\n",
    "    assert multiply(3,4) == 12 \n",
    "```\n",
    "\n",
    "### tox\n",
    "\n",
    "https://tox.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doctest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestResults(failed=0, attempted=4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try to set a wrong expected value\n",
    "# def fun():\n",
    "#     \"\"\"\n",
    "#     >>> fun()\n",
    "#     0\n",
    "#     \"\"\"\n",
    "#     return 42\n",
    "\n",
    "def fun():\n",
    "    \"\"\"\n",
    "    >>> fun()\n",
    "    Traceback (most recent call last):\n",
    "      File \"/home/haskfp/tools/miniconda3/lib/python3.6/doctest.py\", line 1330, in __run\n",
    "        compileflags, 1), test.globs)\n",
    "      File \"<doctest __main__.fun[0]>\", line 1, in <module>\n",
    "        fun()\n",
    "      File \"<ipython-input-3-c8c65832d300>\", line 14, in fun\n",
    "        return 42/0\n",
    "    ZeroDivisionError: division by zero\n",
    "    \"\"\"\n",
    "    return 42/0\n",
    "\n",
    "def fun_with_arg(a, b=0):\n",
    "    \"\"\"\n",
    "    >>> fun_with_arg(2)\n",
    "    2\n",
    "    >>> fun_with_arg(2, 10)\n",
    "    22\n",
    "    >>> fun_with_arg(2, -5)\n",
    "    -8\n",
    "    \"\"\"\n",
    "    return a + b * 2\n",
    "\n",
    "# may be run as below, but in most cases just a part of pytest/etc configuration\n",
    "import doctest\n",
    "doctest.testmod()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# how to run? See https://docs.pytest.org/en/latest/usage.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "\n",
    "# do 3 different test for each argument\n",
    "@pytest.mark.parametrize(\"some_arg\", [1, 2, 3])\n",
    "def test_the_same(some_arg):    \n",
    "    assert some_arg > 0\n",
    "\n",
    "# kind of stub, it's used in the in test_1_that_needs_resource_a\n",
    "@pytest.fixture()\n",
    "def resource_a():\n",
    "    print('\\nresources_a() \"setup\"')\n",
    "\n",
    "def test_1_that_needs_resource_a(resource_a):\n",
    "    print('test_1_that_needs_resource_a()')\n",
    "\n",
    "# initializations and post clean methods\n",
    "def resource_a_setup():\n",
    "    print('resources_a_setup()')\n",
    "\n",
    "def resource_a_teardown():\n",
    "    print('resources_a_teardown()')\n",
    "\n",
    "def setup_module(module):\n",
    "    print('\\nsetup_module()')\n",
    "    resource_a_setup()\n",
    "\n",
    "def teardown_module(module):\n",
    "    print('\\nteardown_module()')\n",
    "    resource_a_teardown()\n",
    "\n",
    "\n",
    "#############################################\n",
    "################## one func and 2 test for it\n",
    "def func(x, y):\n",
    "    return x / y + 1\n",
    "\n",
    "def test_answer():\n",
    "    assert func(10, 5) == 6\n",
    "\n",
    "def test_zero_div():\n",
    "    with pytest.raises(ZeroDivisionError):\n",
    "        func(10, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.012s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7f8ddf2b75c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "import math\n",
    " \n",
    "\n",
    "class TestMath(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        pass\n",
    " \n",
    "    def test_math_sqrt(self):\n",
    "        self.assertEqual(math.sqrt(81), 9.0)\n",
    " \n",
    "    def test_math_ceil_less_5(self):\n",
    "        self.assertEqual(math.ceil(35.1), 36)\n",
    "        \n",
    "    def test_math_ceil_more_5(self):\n",
    "        self.assertEqual(math.ceil(125.7), 126)\n",
    "        \n",
    "    def test_math_ceil_equal_5(self):\n",
    "        self.assertEqual(math.ceil(0.5), 1)\n",
    "\n",
    "\n",
    "# just specific args in order to run in jupyter\n",
    "unittest.main(argv=['first-arg-is-ignored'], exit=False)\n",
    "\n",
    "# in case of a separate file, just use\n",
    "# unittest.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.003s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7f780813ca20>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "import os\n",
    "import unittest.mock as mock\n",
    "\n",
    "\n",
    "def fun(arg):\n",
    "    return str(os.urandom(arg)) + \"<<<\"\n",
    "\n",
    "\n",
    "def simple_urandom(length):\n",
    "    return 'f' * length\n",
    "\n",
    "\n",
    "class TestRandom(unittest.TestCase):\n",
    "\n",
    "    @mock.patch('os.urandom', side_effect=simple_urandom)\n",
    "    def test_urandom(self, urandom_function):\n",
    "        assert fun(5) == 'fffff<<<'\n",
    "        \n",
    "        urandom_function.assert_called_once_with(5)\n",
    "\n",
    "        \n",
    "unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "......\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.011s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7f8ddf33bc18>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"real code\", should be in a separate file \n",
    "import os\n",
    "import os.path\n",
    "\n",
    "\n",
    "def rm(filename):\n",
    "    \"\"\"\n",
    "    Just a nice function, which we will test below\n",
    "    \"\"\"\n",
    "    if os.path.isfile(filename):\n",
    "        os.remove(filename)\n",
    "\n",
    "\n",
    "# testing code\n",
    "import unittest.mock as mock\n",
    "import unittest\n",
    "\n",
    "class RmTestCase(unittest.TestCase):\n",
    "    \n",
    "    @mock.patch('os.path')\n",
    "    @mock.patch('os.remove')    \n",
    "    def test_rm(self, mock_remove, mock_path):\n",
    "        # set up the mock\n",
    "        mock_path.isfile.return_value = False        \n",
    "        \n",
    "        rm(\"any path\")\n",
    "        \n",
    "        # test that the remove call was NOT called.\n",
    "        self.assertFalse(mock_remove.called,\n",
    "                         \"Failed to not remove the file if not present.\")\n",
    "        \n",
    "        # make the file 'exist'\n",
    "        mock_path.isfile.return_value = True\n",
    "        \n",
    "        rm(\"any path\")\n",
    "        \n",
    "        mock_remove.assert_called_with(\"any path\")\n",
    "\n",
    "\n",
    "unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- implement \"Exercise 126: Generate All Sublists of a List\" (see python workbook) and test it, include benchmarking (see https://pypi.python.org/pypi/pytest-benchmark)\n",
    "- create simple flask rest api and test it (see http://flask.pocoo.org/docs/0.12/testing/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
